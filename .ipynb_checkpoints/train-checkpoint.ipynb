{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7680, 100, 100)\n",
      "(1920, 100, 100)\n",
      "(7680,)\n",
      "(1920,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib.image import imread\n",
    "import os\n",
    "def load_data():\n",
    "    data = []\n",
    "    labels = []\n",
    "    onehot_labels = []\n",
    "    path = './data/smiles/smile_facegray'\n",
    "    length = 4800\n",
    "    for filename in os.listdir('./data/smiles/smile_facegray'):\n",
    "        img = imread(path+\"/\"+filename)\n",
    "        data.append(img)\n",
    "        labels.append(0)\n",
    "        onehot_labels.append([1, 0])\n",
    "        if(len(data) == length):\n",
    "            break\n",
    "    path = './data/smiles/no_smile_facegray'\n",
    "    for filename in os.listdir('./data/smiles/no_smile_facegray'):\n",
    "        img = imread(path+\"/\"+filename)\n",
    "        data.append(img)\n",
    "        labels.append(1)\n",
    "        onehot_labels.append([0, 1])\n",
    "        if(len(data) == length*2):\n",
    "            break\n",
    "    data = np.asarray(data, dtype=np.float32)\n",
    "    #data = np.expand_dims(data,axis=1)\n",
    "    #data = np.expand_dims(data, axis=3)\n",
    "    labels = np.asarray(labels)\n",
    "    #labels = np.expand_dims(labels, axis=1)\n",
    "    onehot_labels = np.asarray(onehot_labels)\n",
    "    return data, labels, onehot_labels\n",
    "X, labels, y = load_data()\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_val, y_train, y_val = train_test_split(X,labels,test_size=0.2)\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(y_train.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x15d06e4d0>\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x15d3a6a90>\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data.dataset import *\n",
    "#from torchvision import transforms\n",
    "import torch\n",
    "import torchvision.datasets\n",
    "import torch.utils.data as data\n",
    "import PIL\n",
    "import matplotlib.pyplot as plt\n",
    "from torchsample.modules import ModuleTrainer\n",
    "import numpy as np\n",
    "from matplotlib.image import imread\n",
    "import os\n",
    "from torchsample.callbacks import EarlyStopping\n",
    "from torch.utils.data import DataLoader\n",
    "from torchsample import TensorDataset\n",
    "from torchsample.transforms import *\n",
    "from torchsample.metrics import BinaryAccuracy\n",
    "'''data_transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    RandomAffine(30, translate=(0.1,0.1), shear=0.2, resample=PIL.Image.NEAREST),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    ToTensor()])'''\n",
    "my_transform = Compose([ToTensor(),\n",
    "                        AddChannel(axis=0),\n",
    "                        RandomAffine(rotation_range=30, translation_range=0.1, shear_range=0.2,interp='nearest'),\n",
    "                        RandomFlip(),\n",
    "                       ])\n",
    "#dataset = torchvision.datasets.ImageFolder('./data/smiles',transform=data_transform)\n",
    "#tensor_x_train = torch.Tensor(X_train) # transform to torch tensor\n",
    "#tensor_y_train = torch.Tensor(y_train)\n",
    "#tensor_x_val = torch.Tensor(X_val) # transform to torch tensor\n",
    "#tensor_y_val = torch.Tensor(y_val)\n",
    "train_set = TensorDataset(X_train,y_train ,input_transform=my_transform,target_transform=None)\n",
    "val_set = TensorDataset(X_val,y_val ,input_transform=my_transform,target_transform=None)\n",
    "train_loader = data.DataLoader(train_set, batch_size=32, shuffle=True)\n",
    "val_loader = data.DataLoader(val_set, batch_size=32, shuffle=True)\n",
    "print(train_loader)\n",
    "print(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100: 100%|██████████| 240/240 [01:16<00:00,  3.44 batches/s, loss=23.5776]/Users/ethan/Desktop/convnet/torchsample/torchsample/modules/module_trainer.py:658: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  return Variable(input_batch, volatile=volatile), Variable(target_batch, volatile=volatile, requires_grad=False)\n",
      "Epoch 1/100: : 241 batches [01:24,  2.85 batches/s, loss=0.697, val_loss=0.682]                 \n",
      "Epoch 2/100: : 241 batches [01:21,  2.94 batches/s, loss=0.681, val_loss=0.683]                 \n",
      "Epoch 3/100: : 241 batches [01:22,  2.93 batches/s, loss=0.691, val_loss=0.682]                 \n",
      "Epoch 4/100: : 241 batches [01:32,  2.61 batches/s, loss=0.693, val_loss=0.682]                 \n",
      "Epoch 5/100:   4%|▍         | 9/240 [00:02<01:11,  3.24 batches/s, loss=0.6932]"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(in_channels=1,out_channels=25, kernel_size=3,stride=1,padding=1,bias=True)\n",
    "        self.maxpool1 = torch.nn.MaxPool2d(3)\n",
    "        self.drop1 = torch.nn.Dropout(p=0.25)\n",
    "        self.conv2 = torch.nn.Conv2d(in_channels=25,out_channels=50, kernel_size=3,stride=1,padding=1,bias=True)\n",
    "        self.maxpool2 = torch.nn.MaxPool2d(3)\n",
    "        self.drop2 = torch.nn.Dropout(p=0.25)\n",
    "        self.linear1 = torch.nn.Linear(in_features=50*11*11,out_features=500,bias=True)\n",
    "        self.linear2 = torch.nn.Linear(in_features=500,out_features=2)\n",
    "        self.relu1 = torch.nn.ReLU()\n",
    "        self.relu2 = torch.nn.ReLU()\n",
    "        self.relu3 = torch.nn.ReLU()\n",
    "    def forward(self,x):\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.drop1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = self.drop2(x)\n",
    "        x = x.view(-1,50*11*11)\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.linear2(x)\n",
    "        #x = F.log_softmax(x)\n",
    "        return x\n",
    "lr = 0.01   \n",
    "net = Net()\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "callbacks = [EarlyStopping(monitor='val_acc', patience=5)]\n",
    "metrics = [BinaryAccuracy()]\n",
    "trainer = ModuleTrainer(net)\n",
    "trainer.compile(loss=loss,\n",
    "                optimizer=optimizer,\n",
    "                metrics=metrics,\n",
    "               callbacks=callbacks)\n",
    "trainer.fit_loader(train_loader, val_loader=val_loader, num_epoch=100)\n",
    "\n",
    "'''\n",
    "loss_list = []\n",
    "epoch_list = []\n",
    "accuracy_list = []\n",
    "for epoch in range(100):\n",
    "    running_loss = 0\n",
    "    num_correct = 0\n",
    "    for batch, labels in data_loader:\n",
    "        output = net(batch)\n",
    "        loss = criterion(output,labels)\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        correct = (predicted == labels).sum().item()\n",
    "        num_correct += correct\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    accuracy_list.append(num_correct/9600)\n",
    "    loss_list.append(running_loss)\n",
    "    epoch_list.append(epoch)\n",
    "    \n",
    "    print(\"Epoch: {} Accuracy: {}\".format(epoch, num_correct/9600))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), 'pytorch.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(epoch_list, accuracy_list)\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epoch_list, loss_list)\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from convnet import *\n",
    "from convolution import *\n",
    "from max_pool import *\n",
    "from avg_pool import *\n",
    "from layers import *\n",
    "from fc import *\n",
    "from loss_func import *\n",
    "from relu import *\n",
    "from flat import *\n",
    "from matplotlib import pyplot as plt\n",
    "import math\n",
    "from matplotlib.image import imread\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npmodel = [convolution(num_filters=20, kernel_size=3,padding=1,stride=1),\n",
    "relu(),\n",
    "max_pool(size=3),\n",
    "convolution(num_filters=40, kernel_size=3,padding=1,stride=1),\n",
    "relu(),\n",
    "max_pool(size=3),\n",
    "flat(),\n",
    "fc(input_dim=40*11*11, output_dim=500),\n",
    "relu(),\n",
    "fc(input_dim=500, output_dim=2)\n",
    "]\n",
    "convnet = ConvNet(npmodel)\n",
    "convnet.model[0].filters =  net.conv1.weight.detach().numpy()\n",
    "convnet.model[0].bias = net.conv1.bias.detach().numpy()\n",
    "convnet.model[3].filters =   net.conv2.weight.detach().numpy()\n",
    "convnet.model[3].bias =  net.conv2.bias.detach().numpy()\n",
    "convnet.model[7].weights = net.linear1.weight.detach().numpy().T\n",
    "convnet.model[7].bias = net.linear1.bias.detach().numpy()\n",
    "convnet.model[9].weights = net.linear2.weight.detach().numpy().T\n",
    "convnet.model[9].bias = net.linear2.bias.detach().numpy()\n",
    "convnet.save_model('face.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = ConvNet([])\n",
    "c.load_model('face.pkl')\n",
    "from PIL import Image\n",
    "import face_recognition\n",
    "img = Image.open('./me_smile.png')\n",
    "img = img.convert(\"L\")\n",
    "image = face_recognition.load_image_file('./me_smile.png')\n",
    "faces = face_recognition.face_locations(image)\n",
    "if(len(faces) == 1):\n",
    "    print('lol')\n",
    "    top, right, bottom, left = faces[0]\n",
    "    box = (left, top, right, bottom)\n",
    "    resize_image = img.resize((100, 100), box = box)\n",
    "    resize_image.save('./me_smile_gray.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray = imread('./me_smile_gray.jpg')\n",
    "'''gray = gray.reshape(1, 100*100) \n",
    "gray = scaler.transform(gray)\n",
    "gray = gray.reshape(100,100)\n",
    "img = Image.fromarray(np.uint8(gray * 255), 'L')\n",
    "img.save('./me_smile_norm.jpg')\n",
    "gray = imread('./me_smile_gray.jpg')'''\n",
    "plt.imshow(gray, cmap='gray')\n",
    "'''fig = plt.figure()\n",
    "norm = imread('./me_smile_norm.jpg')\n",
    "plt.imshow(norm, cmap='gray')'''\n",
    "#gray = np.moveaxis(gray, 2, 0)\n",
    "gray = np.asarray([[gray]])\n",
    "#norm = np.asarray([[norm]])\n",
    "print(gray.shape)\n",
    "temp = X[5001:5002].reshape(1,100,100,1)\n",
    "fig = plt.figure()\n",
    "temp_img = np.moveaxis(temp,3,1)\n",
    "print(temp.shape)\n",
    "plt.imshow(temp[0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = torch.nn.Softmax()\n",
    "pred = m(torch.from_numpy(c.forward(temp_img)).float())\n",
    "print(pred)\n",
    "net.eval()\n",
    "output = m(net(torch.from_numpy(temp_img).float()))\n",
    "print(output)\n",
    "\n",
    "pred = torch.from_numpy(c.forward(gray)).float()\n",
    "print(pred)\n",
    "net.eval()\n",
    "output = net(torch.from_numpy(gray).float())\n",
    "print(output)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
